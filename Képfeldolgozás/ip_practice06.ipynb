{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrMrtn/GoogleColab/blob/main/K%C3%A9pfeldolgoz%C3%A1s/ip_practice06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdOll1KGKs60"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABCJ8koLKs64"
      },
      "source": [
        "# Image Processing Practice 6\n",
        "\n",
        "1. Pinhole cameras\n",
        "2. 3D point cloud reconstruction\n",
        "3. The robustness of stereo matching\n",
        "4. Normal vector reconstruction\n",
        "5. Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ2G6KzZKs67"
      },
      "source": [
        "-----------------------\n",
        "\n",
        "# 1. Pinhole cameras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmZagF4sKs67"
      },
      "source": [
        "## 1. 1. Linear algebra reminder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKBkPgmRKs68"
      },
      "source": [
        "Inverse of an $A \\in \\mathbb{R}^{3Ã—3}$ matrix:\n",
        "\n",
        "* notation: $A^{-1}$\n",
        "* property: $A^{-1}A=\\begin{bmatrix} 1&0&0 \\\\ 0&1&0 \\\\ 0&0&1 \\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MTW6Y-tKs69"
      },
      "source": [
        "Matrix-vector multiplication:\n",
        "\n",
        "$$\\begin{bmatrix} a_{11}&a_{12}&a_{13} \\\\ a_{21}&a_{22}&a_{23} \\\\ a_{31}&a_{32}&a_{33} \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix}= v_1 \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\end{bmatrix} + v_2 \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\end{bmatrix} + v_3 \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmfTww2EKs69"
      },
      "source": [
        "## 1.2. How to get the pixel corresponding to a point in the space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtkuvHEFKs6-"
      },
      "source": [
        "**Simplifying assumption:** Let the $(0, 0)$ pixel the bottom left corner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geTsrOl3Ks6_"
      },
      "source": [
        "Figure:\n",
        "\n",
        "<svg height=\"260\" width=\"300\">\n",
        "  <text x=\"60\" y=\"20\" font-weight=\"bold\">Image coordinates</text>\n",
        "  <rect width=\"200\" height=\"200\" fill=\"none\" stroke=\"black\" y=\"40\" x=\"25\"/>\n",
        "  <circle cx=\"25\" cy=\"240\" r=\"10\" fill=\"red\"/>\n",
        "  <text x=\"0\" y=\"220\">(0, 0)=bottom left corner</text>\n",
        "  <text x=\"120\" y=\"250\">x_px</text>\n",
        "  <text x=\"0\" y=\"150\">y_px</text>\n",
        "</svg>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TM_6EmUKs6_"
      },
      "source": [
        "Image space:\n",
        "\n",
        "* horizontally flipped version of the pixels\n",
        "* bottom left corner: $(0, 0)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9netzQsKs7A"
      },
      "source": [
        "Given:\n",
        "\n",
        "* A pinhole camera (e. g. smartphone camera). The camera has the following properties:\n",
        "  * Looks at the +Z-direction\n",
        "  * The up-direction is Y\n",
        "  * Its intrinsic matrix is called K\n",
        "* A point in front of the camera. Relative position to the camera: $\\begin{bmatrix} x_{\\text{space}} \\\\ y_{\\text{space}} \\\\ z_{\\text{space}} \\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdaO3N3cKs7A"
      },
      "source": [
        "Figure:\n",
        "\n",
        "<svg height=\"200\" width=\"600\">\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"100\" y2=\"50\" stroke=\"black\"/>\n",
        "    <!-- Y axis -->\n",
        "    <text x=\"10\" y=\"20\">Y</text>\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"0\" y2=\"0\" stroke=\"black\"/>\n",
        "    <!-- Z axis -->\n",
        "    <text x=\"40\" y=\"90\">Z</text>\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"100\" y2=\"200\" stroke=\"black\"/>\n",
        "    <!-- X axis -->\n",
        "    <text x=\"40\" y=\"160\">X</text>\n",
        "    <!-- Relevant point -->\n",
        "    <circle cx=\"140\" cy=\"70\" r=\"5\" fill=\"blue\"/>\n",
        "    <text x=\"140\" y=\"70\">(x_space, y_space, z_space)</text>\n",
        "    <!--Camera -->\n",
        "    <text x=\"0\" y=\"100\">Camera</text>\n",
        "</svg>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0ffiNIuKs7A"
      },
      "source": [
        "The elements of the intrinsic matrix (reminder): $K=\\begin{bmatrix} f_x&0&c_x \\\\ 0&f_y&c_y \\\\ 0&0&1 \\end{bmatrix}$, where:\n",
        "\n",
        "* $f_x, f_y$: horizontal and vertical focal lengths (they are typically equal)\n",
        "* $c_x, c_y$: the optical center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CG2ZgkiKs7A"
      },
      "source": [
        "The formula to get the pixel for an $(x_{\\text{space}}, y_{\\text{space}}, z_{\\text{space}}$) point.\n",
        "\n",
        "1. Calculate the pixel homogen coordinates.\n",
        "\n",
        "$$\\begin{bmatrix} x_{\\text{h}} \\\\ y_{\\text{h}} \\\\ z_{\\text{space}} \\end{bmatrix} = \\underbrace{\\begin{bmatrix} f_x&0&c_x \\\\ 0&f_y&c_y \\\\ 0&0&1 \\end{bmatrix}}_{K} \\begin{bmatrix} x_{\\text{space}} \\\\ y_{\\text{space}} \\\\ z_{\\text{space}} \\end{bmatrix}$$\n",
        "\n",
        "2. Divide by the last coordinate.\n",
        "\n",
        "$$ \\begin{bmatrix} x_{\\text{px}} \\\\ y_{\\text{px}} \\\\ 1 \\end{bmatrix} = \\frac{1}{z_{\\text{space}}} \\begin{bmatrix} x_{\\text{h}} \\\\ y_{\\text{h}} \\\\ z_{\\text{space}} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RemjeJ2Ks7B"
      },
      "source": [
        "In other words:\n",
        "\n",
        "$$ x_{\\text{px}} = \\frac{f_x x_{\\text{space}}+c_x z_{\\text{space}}}{z_{\\text{space}}} $$\n",
        "\n",
        "$$ y_{\\text{px}} = \\frac{f_y y_{\\text{space}}+c_y z_{\\text{space}}}{z_{\\text{space}}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzP4PYXYKs7B"
      },
      "source": [
        "Python implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZerzxKoKs7B"
      },
      "outputs": [],
      "source": [
        "def get_im_pos(K: np.ndarray, pt_space: np.ndarray) -> np.ndarray:\n",
        "    im_hom = K @ pt_space\n",
        "    im_hom = im_hom / im_hom[-1]\n",
        "    return im_hom[[0, 1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16mkecYoKs7C"
      },
      "source": [
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StGNtARWKs7C"
      },
      "outputs": [],
      "source": [
        "K = np.array([\n",
        "    [320, 0, 320],\n",
        "    [0, 320, 240],\n",
        "    [0, 0, 1]\n",
        "], dtype=np.float32)\n",
        "get_im_pos(K, np.array([\n",
        "    [2],\n",
        "    [1.5],\n",
        "    [8]\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSOkvGqXKs7C"
      },
      "source": [
        "Now, let's multiply the pooint in the space, by 2. It falls onto the same pixel. Why is this unsurprising?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdr2kGmJKs7C"
      },
      "outputs": [],
      "source": [
        "get_im_pos(K, np.array([\n",
        "    [2],\n",
        "    [1.5],\n",
        "    [8]\n",
        "])*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96hFq4TNKs7D"
      },
      "source": [
        "Now, modify the X coordinate of the point while keeping the Y other coordinates constant. As you can see, the Y coordinate on the image does not change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTDcgEr7Ks7D"
      },
      "outputs": [],
      "source": [
        "get_im_pos(K, np.array([\n",
        "    [2+3],\n",
        "    [1.5],\n",
        "    [8]\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDFDuVczKs7D"
      },
      "source": [
        "## 1.3. Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4wO8LhnKs7D"
      },
      "source": [
        "**Exercise 1:** Assume that we have two cameras with the same known intrinsics. They point at the +Z-direction. They have the same Y coordinate and have distance B. Assume that both see a point. What is the Z-coordinate of the point ($z_{\\text{space}}$) relative to the cameras?\n",
        "\n",
        "Figure:\n",
        "\n",
        "<svg height=\"200\" width=\"600\">\n",
        "    <!-- Y axis -->\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"100\" y2=\"50\" stroke=\"black\"/>\n",
        "    <text x=\"10\" y=\"20\">Y</text>\n",
        "    <!-- Z axis -->\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"0\" y2=\"0\" stroke=\"black\"/>\n",
        "    <text x=\"40\" y=\"90\">Z</text>\n",
        "    <!-- X axis -->\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"100\" y2=\"200\" stroke=\"black\"/>\n",
        "    <text x=\"40\" y=\"160\">X</text>\n",
        "    <!-- Relevant point -->\n",
        "    <circle cx=\"140\" cy=\"70\" r=\"5\" fill=\"blue\"/>\n",
        "    <text x=\"140\" y=\"70\">(x_space, y_space, z_space)</text>\n",
        "    <!--Left camera -->\n",
        "    <text x=\"0\" y=\"100\">Left camera</text>\n",
        "    <circle cx=\"0\" cy=\"100\" r=\"5\" fill=\"red\"/>\n",
        "    <!--Right camera -->\n",
        "    <text x=\"50\" y=\"150\">Right camera</text>\n",
        "    <circle cx=\"50\" cy=\"150\" r=\"5\" fill=\"red\"/>\n",
        "    <!-- B -->\n",
        "    <line x1=\"0\" y1=\"100\" x2=\"50\" y2=\"150\" stroke=\"red\"  stroke-dasharray=\"4\"/>\n",
        "    <text x=\"25\" y=\"125\" >B</text>\n",
        "</svg>\n",
        "\n",
        "Let:\n",
        "\n",
        "* The x coordinate of the point relative to the **left** camera: $x_{\\text{space}}$\n",
        "* The x coordinate of the point relative to the **right** camera: $x'_{\\text{space}}$\n",
        "* the x coordinate of the pixel for the point on the image of the **left** camera: $x_{\\text{px}}$\n",
        "* the x coordinate of the pixel for the point on the image of **right** camera: $x'_{\\text{px}}$\n",
        "* The camera intrinsics: $K=\\begin{bmatrix} f_x&0&c_x \\\\ 0&f_y&c_y \\\\ 0&0&1 \\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoCxPWtAKs7E"
      },
      "source": [
        "\n",
        "**Solution:** The formulas for the x coordinates of the pixels (copied from above):\n",
        "\n",
        "$$x_{\\text{px}} =\\frac{f_x x_{\\text{space}}+c_x z_{\\text{space}}}{z_{\\text{space}}}$$\n",
        "\n",
        "$$x'_{\\text{px}} =\\frac{f_x x'_{\\text{space}}+c_x z_{\\text{space}}}{z_{\\text{space}}}$$\n",
        "\n",
        "Now, subtract the two equations:\n",
        "\n",
        "$$x_{\\text{px}}-x'_{\\text{px}} = \\frac{f_x \\cdot (x_{\\text{sapce}}-x'_{\\text{sapce}})}{z_{\\text{space}}}$$\n",
        "\n",
        "Substitute $B=x_{\\text{sapce}}-x'_{\\text{sapce}}$\n",
        "\n",
        "$$x_{\\text{px}}-x'_{\\text{px}} = \\frac{f_x B}{z_{\\text{space}}}$$\n",
        "\n",
        "Reorganize the equation\n",
        "\n",
        "$$z_{\\text{space}} = \\frac{f_x B}{x_{\\text{px}}-x'_{\\text{px}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jctH4VfqKs7E"
      },
      "source": [
        "**Important note:** $x_{\\text{px}}-x'_{\\text{px}}$ is called *disparity*, and it is proportional to $1/z_{\\text{space}}$ *regardless of the camera intrinsics*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgH8ZN3yKs7E"
      },
      "source": [
        "**Exercise 2:** Assume that, there is a point and we know:\n",
        "\n",
        "* It is at the $\\begin{bmatrix} x_{\\text{px}} \\\\ y_{\\text{px}} \\end{bmatrix}$ pixel.\n",
        "* Its Z coordinate relative to the camera is $z_{\\text{space}}$.\n",
        "* The intrinsic matrix is K.\n",
        "\n",
        "How to calculate its X and Y coordinates ($x_{\\text{space}}, y_{\\text{space}}$) relative to the camera?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CUS1rOtKs7E"
      },
      "source": [
        "**Solution:** Reorganize the original projection formula.\n",
        "\n",
        "1. Get the on-image position in homogen coordinates:\n",
        "\n",
        "$$z_{\\text{space}} \\begin{bmatrix}x_{\\text{px}} \\\\ y_{\\text{px}} \\\\ 1 \\end{bmatrix}$$\n",
        "\n",
        "2. Write the projection formula:\n",
        "\n",
        "$$z_{\\text{space}} \\begin{bmatrix}x_{\\text{px}} \\\\ y_{\\text{px}} \\\\ 1 \\end{bmatrix} = K\\begin{bmatrix} x_{\\text{space}} \\\\ y_{\\text{space}} \\\\ z_{\\text{space}} \\end{bmatrix} $$\n",
        "\n",
        "3. Multiply with $K^{-1}$\n",
        "\n",
        "\n",
        "$$K^{-1} z_{\\text{space}} \\begin{bmatrix}x_{\\text{px}} \\\\ y_{\\text{px}} \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} x_{\\text{space}} \\\\ y_{\\text{space}} \\\\ z_{\\text{space}} \\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSy_YG-aKs7F"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# 2. 3D reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1T_cBYEKs7F"
      },
      "source": [
        "Download the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK8529O8Ks7F"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/mntusr/tartanair-stereo-pair/refs/heads/main/tartan_000072_left.jpg\n",
        "!wget https://raw.githubusercontent.com/mntusr/tartanair-stereo-pair/refs/heads/main/tartan_000072_right.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s-09Ky2Ks7F"
      },
      "source": [
        "Load the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkMJLKV0Ks7G"
      },
      "outputs": [],
      "source": [
        "# the image pair from the TartanAir-V1 dataset [1]\n",
        "# (converted to jpg)\n",
        "im_left = cv2.imread(\"tartan_000072_left.jpg\")\n",
        "im_left_rgb = cv2.cvtColor(im_left, cv2.COLOR_BGRA2RGB)\n",
        "im_left_gray = cv2.cvtColor(im_left, cv2.COLOR_BGRA2GRAY)\n",
        "\n",
        "im_right = cv2.imread(\"tartan_000072_right.jpg\")\n",
        "im_right_rgb = cv2.cvtColor(im_right, cv2.COLOR_BGRA2RGB)\n",
        "im_right_gray = cv2.cvtColor(im_right, cv2.COLOR_BGRA2GRAY)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(im_left_rgb)\n",
        "print(f\"{im_right_rgb.shape=}\")\n",
        "plt.title(\"Left\")\n",
        "plt.subplot(1, 2,2)\n",
        "plt.imshow(im_right_rgb)\n",
        "print(f\"{im_right_rgb.shape=}\")\n",
        "plt.title(\"Right\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDmJ11s3Ks7G"
      },
      "source": [
        "Calculate the disparity value (from exercise 1) for each pixel, where possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS6fixYlKs7G"
      },
      "outputs": [],
      "source": [
        "# algorithm: stereo block matching\n",
        "stereo = cv2.StereoBM.create()\n",
        "\n",
        "# StereoBM assumes the configuration of exercise 1.\n",
        "# Disparity calculation (simplified steps):\n",
        "# 1. Take square blocks of one image\n",
        "# 2. Look for them in the SAME ROW on the OTHER image (similarly to template matching)\n",
        "# 3. Store the X position change.\n",
        "# Why is no intrinsic matrix needed?\n",
        "disparity = stereo.compute(im_left_gray, im_right_gray)\n",
        "\n",
        "# show the disparity map\n",
        "disp_out = plt.imshow(disparity)\n",
        "plt.colorbar(disp_out);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFW4KyRKs7G"
      },
      "source": [
        "Get the dimensions of the disparity map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC0FdGa7Ks7H"
      },
      "outputs": [],
      "source": [
        "disp_height, disp_width = disparity.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW6nLiRXKs7H"
      },
      "source": [
        "Calculating the depth from the disparity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZITjAkxKs7N"
      },
      "outputs": [],
      "source": [
        "depth = (100/disparity) # we want to visualize, so we do not care about scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K3v7rdwKs7N"
      },
      "source": [
        "Calculate the homogen coordinates as a point cloud of homogen points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEd_Cld2Ks7N"
      },
      "outputs": [],
      "source": [
        "tartanair_camera = np.array([\n",
        "    [320, 0, 320],\n",
        "    [0, 320, 240],\n",
        "    [0, 0, 1]\n",
        "], dtype=np.float32)\n",
        "\n",
        "def depth_2_point_cloud(depth: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    x, y = np.meshgrid(\n",
        "        np.arange(0, disp_width),\n",
        "        disp_height - np.arange(0, disp_height),\n",
        "    )\n",
        "    depth_flat = depth.flatten()\n",
        "    x_im_flat = x.flatten()*depth_flat\n",
        "    y_im_flat = y.flatten()*depth_flat\n",
        "\n",
        "    x_im_flat[depth_flat<0] = np.nan\n",
        "    y_im_flat[depth_flat<0] = np.nan\n",
        "    depth_flat[depth_flat<0] = np.nan\n",
        "\n",
        "    homogen_point_cloud = np.stack([x_im_flat, y_im_flat, depth_flat], axis=0).T\n",
        "    # multiply each element of the point cloud with the inverse of the intrinsic matrix\n",
        "    space_point_cloud = (np.linalg.inv(tartanair_camera) @ homogen_point_cloud.T).T\n",
        "    # reduce the number of points\n",
        "    point_indices = np.random.default_rng().choice(len(space_point_cloud), 40000)\n",
        "    space_point_cloud = space_point_cloud[point_indices]\n",
        "\n",
        "    # get the color for each point\n",
        "    color_values = np.stack([\n",
        "        im_left_rgb[:, :, 0].flatten(),\n",
        "        im_left_rgb[:, :, 1].flatten(),\n",
        "        im_left_rgb[:, :, 2].flatten(),\n",
        "    ], axis=-1)\n",
        "    color_values = color_values[point_indices]\n",
        "\n",
        "    return space_point_cloud, color_values\n",
        "\n",
        "space_point_cloud, color_values = depth_2_point_cloud(depth)\n",
        "\n",
        "# we use plotly since its interactive mode works better in the browser\n",
        "fig = go.Figure()\n",
        "fig.add_trace(\n",
        "    go.Scatter3d(\n",
        "        x=space_point_cloud[:, 0],\n",
        "        y=space_point_cloud[:, 1],\n",
        "        z=space_point_cloud[:, 2],\n",
        "        mode=\"markers\"\n",
        "    )\n",
        ")\n",
        "fig = fig.update_scenes(\n",
        "    aspectmode=\"data\", xaxis_autorange=\"reversed\"\n",
        ").update_traces(marker={\"size\": 1, \"color\": color_values}).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hyyC6JHKs7O"
      },
      "source": [
        "# 3. The robustness of stereo matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swgj1FAlKs7O"
      },
      "source": [
        "Extract the stereo matching to a separate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyz02AhyKs7O"
      },
      "outputs": [],
      "source": [
        "def stereo_match(im_left_gray: np.ndarray, im_right_gray: np.ndarray) -> None:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Left\")\n",
        "    plt.imshow(im_left_gray, cmap=\"gray\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Right\")\n",
        "    plt.imshow(im_right_gray, cmap=\"gray\")\n",
        "    plt.show()\n",
        "    plt.title(\"Match result\")\n",
        "    plt.imshow(stereo.compute(im_left_gray, im_right_gray))\n",
        "    plt.show()\n",
        "\n",
        "# try on the original pair\n",
        "stereo_match(\n",
        "    im_left_gray=im_left_gray,\n",
        "    im_right_gray=im_right_gray\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEVXnDcmKs7P"
      },
      "source": [
        "**Side note:** Affine transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Uvc46OmKs7P"
      },
      "outputs": [],
      "source": [
        "pt = np.array([\n",
        "    [2],\n",
        "    [3],\n",
        "    [1] # homogen coordinate\n",
        "])\n",
        "\n",
        "# scale still works\n",
        "scaled_pt = np.array([\n",
        "    [5, 0, 0],\n",
        "    [0, 7, 0],\n",
        "    [0, 0, 1],\n",
        "]) @ pt\n",
        "print(f\"{scaled_pt=}\")\n",
        "\n",
        "# move points with matrix multiplication\n",
        "moved_pt = np.array([\n",
        "    [1, 0, 9],\n",
        "    [0, 1, 2],\n",
        "    [0, 0, 1],\n",
        "]) @ pt\n",
        "print(f\"{moved_pt=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTrP8aQGKs7P"
      },
      "source": [
        "The effect of moving one of the stereo pairs vertically by a few pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWVCCa9QKs7P"
      },
      "outputs": [],
      "source": [
        "def move_im(im: np.ndarray, dx: int, dy: int) -> np.ndarray:\n",
        "    im_modified = cv2.warpAffine( # affine transform each pixel\n",
        "        im, np.array([\n",
        "            [1, 0, dx],\n",
        "            [0, 1, dy]\n",
        "        ], dtype=np.float32), (im.shape[1], im.shape[0])\n",
        "    )\n",
        "    return im_modified\n",
        "\n",
        "stereo_match(\n",
        "    im_left_gray=im_left_gray,\n",
        "    im_right_gray=move_im(\n",
        "        im=im_right_gray,\n",
        "        dx=0,\n",
        "        dy=4,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FThHRG2IKs7Q"
      },
      "source": [
        "Why do we experience this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOYjKBy3Ks7Q"
      },
      "source": [
        "Moving the right image horizontally, by a few pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrmfDDbWKs7Q"
      },
      "outputs": [],
      "source": [
        "stereo_match(\n",
        "    im_left_gray=im_left_gray,\n",
        "    im_right_gray=move_im(\n",
        "        im=im_right_gray,\n",
        "        dx=4,\n",
        "        dy=0,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaBWmAngKs7Q"
      },
      "source": [
        "Why is not there any problem here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xuTnNnwKs7R"
      },
      "source": [
        "Cropping the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBu5sNMvKs7R"
      },
      "outputs": [],
      "source": [
        "stereo_match(\n",
        "    im_left_gray=im_left_gray[20:-50, 40:-20],\n",
        "    im_right_gray=im_right_gray[20:-50, 40:-20]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8W0X8ttKs7R"
      },
      "source": [
        "Why is not there any problem here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMlsZPvWKs7R"
      },
      "source": [
        "# 4. Estimating the surface normals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTFfffe6Ks7S"
      },
      "source": [
        "## 4.1. Theory of normals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lB76h6KKs7S"
      },
      "source": [
        "Properties of the normal vector of a surface:\n",
        "\n",
        "* Orthogonal to the surface in its point\n",
        "* Has length 1\n",
        "* Points **outside** of the surface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2WyXqUoKs7S"
      },
      "source": [
        "Calculating the normal vector of a surface at point O using two additional points on the surface.\n",
        "\n",
        "\n",
        "<?xml version=\"1.0\"?>\n",
        "<svg width=\"450\" height=\"230\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:svg=\"http://www.w3.org/2000/svg\">\n",
        " <!-- Created with SVG-edit - https://github.com/SVG-Edit/svgedit-->\n",
        "\n",
        " <g class=\"layer\">\n",
        "  <title>Layer 1</title>\n",
        "  <path d=\"m57.84,130.57l147.16,-66.57l197,87l-344.16,-20.43z\" fill=\"#ffff00\" id=\"svg_11\" stroke=\"#000000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\"/>\n",
        "  <ellipse cx=\"55.84\" cy=\"129.97\" fill=\"#0000ff\" id=\"svg_1\" rx=\"18\" ry=\"18\" stroke=\"#000000\" stroke-width=\"5\"/>\n",
        "  <ellipse cx=\"208.43\" cy=\"65.12\" fill=\"#0000ff\" id=\"svg_6\" rx=\"18\" ry=\"18\" stroke=\"#000000\" stroke-width=\"5\"/>\n",
        "  <ellipse cx=\"402.43\" cy=\"149.12\" fill=\"#0000ff\" id=\"svg_7\" rx=\"18\" ry=\"18\" stroke=\"#000000\" stroke-width=\"5\"/>\n",
        "  <line fill=\"none\" id=\"svg_12\" stroke=\"#ff0000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\" x1=\"55.84\" x2=\"54.84\" y1=\"125.57\" y2=\"24.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_13\" stroke=\"#ff0000\" stroke-width=\"5\" x1=\"32.84\" x2=\"53.84\" y1=\"47.57\" y2=\"25.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_14\" stroke=\"#ff0000\" stroke-width=\"5\" x1=\"77.84\" x2=\"52.84\" y1=\"48.57\" y2=\"25.57\"/>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_15\" stroke=\"#ff0000\" stroke-width=\"0\" style=\"cursor: move;\" text-anchor=\"middle\" x=\"28.84\" xml:space=\"preserve\" y=\"166.57\">O</text>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_16\" stroke=\"#ff0000\" stroke-width=\"0\" text-anchor=\"middle\" x=\"207.43\" xml:space=\"preserve\" y=\"39.23\">P1</text>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_18\" stroke=\"#ff0000\" stroke-width=\"0\" style=\"cursor: move;\" text-anchor=\"middle\" x=\"404.44\" xml:space=\"preserve\" y=\"199.23\">P2</text>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_19\" stroke=\"#ff0000\" stroke-width=\"0\" style=\"cursor: move;\" text-anchor=\"middle\" x=\"22.44\" xml:space=\"preserve\" y=\"87.23\">N</text>\n",
        "  <line fill=\"none\" id=\"svg_22\" stroke=\"#ff0000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\" x1=\"76.84\" x2=\"181.84\" y1=\"109.57\" y2=\"61.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_23\" stroke=\"#ff0000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\" x1=\"78.84\" x2=\"88.84\" y1=\"105.57\" y2=\"79.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_24\" stroke=\"#ff0000\" stroke-width=\"5\" x1=\"112.84\" x2=\"80.84\" y1=\"114.57\" y2=\"106.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_25\" stroke=\"#ff0000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\" x1=\"359.84\" x2=\"83.84\" y1=\"166.57\" y2=\"150.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_26\" stroke=\"#ff0000\" stroke-width=\"5\" x1=\"87.84\" x2=\"110.84\" y1=\"150.57\" y2=\"138.57\"/>\n",
        "  <line fill=\"none\" id=\"svg_27\" stroke=\"#ff0000\" stroke-width=\"5\" transform=\"matrix(1 0 0 1 0 0)\" x1=\"85.84\" x2=\"109.84\" y1=\"150.57\" y2=\"170.57\"/>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_28\" stroke=\"#ff0000\" stroke-width=\"0\" style=\"cursor: move;\" text-anchor=\"middle\" x=\"154.44\" xml:space=\"preserve\" y=\"63.23\">a</text>\n",
        "  <text fill=\"#000000\" font-family=\"Serif\" font-size=\"24\" id=\"svg_29\" stroke=\"#ff0000\" stroke-width=\"0\" text-anchor=\"middle\" x=\"200.36\" xml:space=\"preserve\" y=\"184.23\">b</text>\n",
        " </g>\n",
        "</svg>\n",
        "\n",
        "The calculation of the normal vector:\n",
        "\n",
        "1. Take the cross product $C$ of $a$ and $b$\n",
        "\n",
        "$$C=aÃ—b=\\begin{bmatrix} a_2b_3-a_3b_2 \\\\ a_3b_1-a_1b_3 \\\\ a_1b_2-a_2b_1 \\end{bmatrix}$$\n",
        "\n",
        "2. Normalize the cross product\n",
        "\n",
        "$$ \\hat C = \\frac{C}{\\lVert C \\rVert_2} $$\n",
        "\n",
        "3. Use the normalized cross product ($N=\\hat C$) or its negate ($N=-\\hat C$) to make sure that the normal vector points **outside** of the surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky5LZAhQKs7T"
      },
      "source": [
        "## 4.2. Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmwZSyGYKs7T"
      },
      "outputs": [],
      "source": [
        "def get_surface_normals() -> np.ndarray:\n",
        "    # invert the intrinsic matrix\n",
        "    proj_mat_inv = np.linalg.inv(tartanair_camera)\n",
        "\n",
        "    # define a helper function that restores a point\n",
        "    # from the pixel and the corresponding depth value\n",
        "    def restore_point(x_px: int, y_px: int, z_space: float) -> np.ndarray:\n",
        "        # flip the y coordinate\n",
        "        y_px = disparity.shape[0] - y_px\n",
        "\n",
        "        # basically the same as exercise 2\n",
        "        pt_homogen = np.array([\n",
        "            [x_px*z_space],\n",
        "            [y_px*z_space],\n",
        "            [z_space]\n",
        "        ])\n",
        "        pt_space = proj_mat_inv @ pt_homogen\n",
        "\n",
        "        return pt_space\n",
        "\n",
        "    surface_normals = np.zeros((disparity.shape[0], disparity.shape[1], 3), dtype=np.float32)\n",
        "\n",
        "    # do the calculation for each pixel\n",
        "    # (it was faster if we implemented this with array operations\n",
        "    # but also harder to read)\n",
        "    for x in range(1, surface_normals.shape[1]):\n",
        "        for y in range(1, surface_normals.shape[0]):\n",
        "            # check if we have a valid disparity for the following points\n",
        "            #   (x, y)\n",
        "            #   (x-1, y)\n",
        "            #   (x, y-1)\n",
        "            if min(disparity[y, x], disparity[y-1, x], disparity[y, x-1]) < 0.1:\n",
        "                continue\n",
        "\n",
        "            # get the spatial points for the pixels\n",
        "            #   (x, y)\n",
        "            #   (x-1, y)\n",
        "            #   (x, y-1)\n",
        "            o = restore_point(x, y, depth[y, x])\n",
        "            p1 = restore_point(x, y-1, depth[y-1, x])\n",
        "            p2 = restore_point(x-1, y, depth[y, x-1])\n",
        "\n",
        "            # calculate the vectors pointing to the restored version of (x, y)\n",
        "            a = (o-p1).flatten()\n",
        "            b = (o-p2).flatten()\n",
        "\n",
        "            # compute the normal vector\n",
        "            # look for a vector that is orthogonal for both diff1 and diff2\n",
        "            n = np.cross(a, b)\n",
        "            n = n/np.linalg.norm(n, ord=2)\n",
        "            # configure the direction of the normal vector to point to the camera\n",
        "            #    idea: the camera is not inside the ground\n",
        "            if np.sum(n*(-o.flatten())) < 0:\n",
        "                n = -n\n",
        "            n = n/np.linalg.norm(n, ord=2)\n",
        "\n",
        "            # store the normal vector\n",
        "            surface_normals[y, x] = n\n",
        "\n",
        "    return surface_normals\n",
        "\n",
        "surface_normals = get_surface_normals()\n",
        "plt.imshow(surface_normals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzL8UHA0Ks7T"
      },
      "source": [
        "Why are the normal vectors so noisy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKFTLkCsKs7T"
      },
      "source": [
        "# 5. Sources\n",
        "\n",
        "<details>\n",
        "    <summary>[1] TartanAir-V1 dataset</summary>\n",
        "    Wang, W., Zhu, D., Wang, X., Hu, Y., Qiu, Y., Wang, C., Hu, Y., Kapoor, A., & Scherer, S. (2020). TartanAir: A Dataset to Push the Limits of Visual SLAM<br><a href=\"https://theairlab.org/tartanair-dataset/\">https://theairlab.org/tartanair-dataset/</a>\n",
        "</details>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}