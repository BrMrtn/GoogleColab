{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrMrtn/GoogleColab/blob/main/MI/BSc_MI_labor_4_D%C3%B6nt%C3%A9si_f%C3%A1k_HU_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![flexsys_logo.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFoAAABFCAYAAADKKPFMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAGOAAABjgBco5mFwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAAUySURBVHic7ZxNiBxFGIbfr2dMgpOkN+q6xhBD1MN2dA2J6MGLXgRPXtRcRcL6gyBGFA9hd34i6EEQBUFQEAQPUdCIgkJWDx4EUdlFyQwxEhHMZvPLzmZ3NrLpej2soJmuqrF7Zmp7l3qO885X9fXbM1Vf/1QJPFdRC3ftI3hYpwkwMd5sPJil3aC7tNYeBMWsgVnb9UY7whvtCG+0I7zRjihmDaxt3vUZhdtShAwAYpxoAEAKeHj8Yv1Y1pzyTGajKWoEkJ0po6yqirE+az55xw8djvBGO8Ib7QhvtCNyZXQRKlf59JLMVQfsJcQJAJcBKbULArWDkIIuKA4Kg13kk4CAVAFtSVkBVC/76kQ3Rttq4mfLzcZRnVANo9MAbtI2SMx0kU+CWhj9IMDdWk1k7/hsfbKX/dlYs3/VvOGNdoQ32hHeaEd4ox3RTdXRc0h8WA2jVqoYYLLSbIxqRZG3hdiqkwpLwXSGFO+qhtFHOmFT89LjL+DPRVNgrowGGKWNEGDBpJVn6+93l0+CIQCP6YSlG0r7cd4cuBaGjjtXOoH/w6o3WgDtVWbeWPVGrxa80Y7I2WTYW2pbhkegsE6nqVKpUZn+KVWF0w25MpqQZwD+ppEeEOCgPgYnje0p+RzADq3YurwHwFTKFH8G5BWdsHh+6yJw3BiYK6MDwffjs43EHbVqGF1vCbvUx5TaOVNu1j/WS3VroB+jHeGNdoQ32hHeaEd4ox3hjXaEN9oR3mhHeKMd4Y12hDfaEd5oR3ijHeGNdoQ32hHeaEd4ox3hjXbESjzKMr7AriCGVQTqFtNvQoCd1TB6TacR2GLqTMjnqmF0NhFDRmJadypIs4D1KpwbXW42tG/7W2GwzXR6CGwH8LJOsy7TBZ/QxtgW9xJD1iYtODf69VvvmyisX3dj++dq6cpS69y5R8eax393nZMLnBtdGhq8/envjiReAfji+crZyQ8Ob3SdTxrYxRN3PxmmIAB+7SI2H0iHnQ9WO7kxGgIoy35Gq51cvalkIpBr3iT/+lGnSSAtEn+4yEMoc1lji7VwWLvgEQBUXFiszB+zv+vkglhtYCHQ17DEhfFm4xOddOi64VEV6xZ0igqIN8bmGifalUoY7RXwSW1fBZnC8qrgBLWBO3aT6iHDEagiIV/DcKEgBV4EcJshuKeICAIWtUMHg3g3IIMEv9LIYwDe08WpGKOA3KORWkrwKTSmFYUjMeUpbR6KUwDe0WqM74VIicS37ZoArxZFsEDyZl0wgMSV00ohgnp5tjHR/nktjF5K3xji7DvYWaD8UmnWtTm6nwzJ1IdI6a0tthlXKdNtgE5tmuMISH6qjr5gO3h9hWPfrTF7VVSkgu0UmxXKEQbQb/twBadTZyICZemP7F3pZ9sW00anIDF8RQBm3yUs4FugYSOTzZtmMJ+1ZTcIO/qWgJ29NpLZaKEcJYrfJD4HRzC/eAjAl+kaNB+EQMi+zF6964sdxhWr0bZAAU6Wm/VEGVQdiA5k8UREGFhyNf0tO2DIRMzSskr9r7fDjVdL/j2fDKWLrX9dQhSynLjMQ0dfqg7rHszm6q4v+zanJWtfIvaysOdGZzZFBMpSWWSsFEy5WNvKFAT7BNuXX7RtPLU+KnKIZDhx3VUdATcK5ZShYeOJIDBcC6PETmAktpN80RQ3Nz2z4d37HznDWMX8zzgyd2qmZJoMCaFADtTCaF97c5Tklm//Igsgp6X9ypK41nRLVqAIyCyA1vJXsQTwn63b5IKpJwKE4GAtjPZrtD1/Ay3aiOaEeIwPAAAAAElFTkSuQmCC) Mesterséges Intelligencia és Rendszertervezés Tanszék, ©2024. BME-MIT, Alekszejenkó Levente, Dr. Hullám Gábor  \n",
        "# **VIMIAC16 - Mesterséges Intelligencia**\n",
        "## 2024. Őszi félév\n",
        "## **4. Laborgyakorlat**"
      ],
      "metadata": {
        "id": "fjkn9FePAugi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Döntési fák**"
      ],
      "metadata": {
        "id": "M7-cGelEWgCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!wget https://share.mit.bme.hu/index.php/s/9ag8JsRD9mXWj85/download/dataset.csv"
      ],
      "metadata": {
        "id": "WGVDROoiWeJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Elméleti háttér**\n",
        "\n",
        "A döntési fák (decision tree) talán az emberi gondolkodáshoz legközelebb álló, intuitív osztályozók (classifier). Általában relatíve kevés adattal is hatékonyan taníthatóak, és a struktúrájuk *emberi szemmel* is érthető. Egyszerűségük ellenére is igen jó előrejelző teljesítményt nyújtanak, így sikeresen alkalmazhatóak különböző területeken az orvosi döntéstámogatástól kezdve, az üzleti életen át az ajánló rendszerekig (recommender systems).\n",
        "\n",
        "\n",
        "![dtree](https://share.mit.bme.hu/index.php/apps/files_sharing/publicpreview/5GAKgGAAErwLr6n?file=/&fileId=3815291&x=1920&y=1080&a=true&etag=c084366203833f27c25fe8d16bbeb250)\n",
        "\n",
        "### Áttekintés\n",
        "\n",
        "Osztályozási feladatoknál az adatunk megadható táblázatos formában, például így:\n",
        "\n",
        "| Tulajdonság$_A$| Tulajdonság$_B$| Címke |\n",
        "| :-----------: | :-----------: | :---: |\n",
        "|      1        |      2        |   o   |\n",
        "|      2        |      7        |   o   |\n",
        "|     12        |      4        |   x   |\n",
        "|     ...       |     ...       |  ...  |\n",
        "\n",
        "Ebben a példában a Tulajdonság$_A$ és Tulajdonság$_B$ oszlopokban valamilyen ismert tulajdonságok (feature) szerepelnek, míg a Címke (label) oszlop a döntés kimenetelét szimbolizálja. Például, ha $A = 2$ és $B = 7$, akkor a célváltozónk az o kategóriába fog esni, azonban $A = 12$ és $B = 4$ esetén az x-be.\n",
        "\n",
        "Ugyanez természetesen az $(A \\times B)$ térbe is felrajzolható:\n",
        "\n",
        "![illustration](https://share.mit.bme.hu/index.php/apps/files_sharing/publicpreview/jJwKaRxqQS7WJy7?file=/&fileId=3815472&x=1920&y=1080&a=true&etag=53f8a992384228edc0a5f1c9920f6c77)\n",
        "\n",
        "Két tulajdonság esetén a probléma könnyen ábrázolható a síkon, viszont $n$ tulajdonság esetén $n$-dimenziós terekkel kell dolgoznunk. Ezt persze már nehéz elképzelni grafikusan, de egy konkrét változó lefixálása mellett a bemutatott módszer általánosítható $n-1$ dimenziós hipersíkokkal.\n"
      ],
      "metadata": {
        "id": "8l0BFH2j6Xru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Minták szeparációja**\n",
        "\n",
        "Körvonalazódni látszik tehát egy algoritmus, mely a tulajdonságtér felosztásával megoldja a klasszifikációs feladatunkat. A célunk tehát az, hogy olyan rekurzív felosztásokat hozzunk létre, melyek végeredményként a lehető legjobban elválasztják a különbözően címkézett adatpontokat. Ezt úgy is megfogalmazhatjuk, hogy a felosztások két oldalán kialakuló adatpontok rendezettlensége legyen a lehető legkisebb.\n",
        "\n",
        "Első közelítésben (és nem mellesleg ahhoz, hogy döntési fákat kapjunk) próbáljuk meg a tulajdonságok terét a tulajdonságok értékeinél egy-egy egyenessel (grafikusan: a tengelyekkel párhuzamos egyenesekkel) két részre bontani.\n",
        "\n",
        "![separations](https://share.mit.bme.hu/index.php/apps/files_sharing/publicpreview/fYDnEzPdzHXKNGD?file=/&fileId=3815457&x=1920&y=1080&a=true&etag=eb7584e97ad02851a9ae9daae8dca167)\n",
        "\n",
        "Figyeljük meg a különböző felosztáspéldákat! Az 1) esetben nem nyertünk sokat, legfeljebb annyit, hogy egyetlen piros o-ról tudjuk, hogy ettől az egyenestől balra található, azonban tőle jobbra teljesen vegyesen vannak o és x címkéjű elemek.\n",
        "\n",
        "A 2) és 3) felosztási lehetőséget jobban megvizsgálva láthatjuk, hogy a 2)-es bizonyos értelemben jobb, mint a 3)-as: a 2)-es egyenestől balra 2 darab x címkéjű elem található, míg tőle jobbra egyetlen o. Eközben a 3)-as esetében az elválasztó egyenes alatt 3 o található, felette pedig 2 x.\n",
        "\n",
        "Ahhoz, hogy ezt a minőségi eltérést számszerűsíteni tudjuk, meg kell mérnünk a rendezetlenséget, hiszen a rendezetlenség kapcsolatba hozható a helyesen és helytelenül osztályozott példákkal."
      ],
      "metadata": {
        "id": "u62XXRz4Uyq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Entrópia**\n",
        "\n",
        "Kódolástechnikából vagy információelméletből ismerős fogalom lehet a rendezetlenség mértékeként a (Shannon-féle) entrópia ($H$):\n",
        "\n",
        "> $H = - \\sum_{x \\in X} p(x) \\cdot \\log_2 p(x)$,\n",
        "\n",
        "ahol $X$ a *címkeértékek* halmaza.\n",
        "\n",
        "Ha egy halmaz teljesen rendezett, azaz csak egyféle címkét tartalmaz, akkor az entrópiája $H = 0$ lesz.\n",
        "\n",
        "**Implementáljon egy kétosztályos entrópiaszámító függvényt!** Megoldásához bátran használja a `np.log2()` függvényt!"
      ],
      "metadata": {
        "id": "iXRQmqX3VMxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entropy(n_label0: int, n_label1: int) -> float:\n",
        "  '''\n",
        "    Returns the entropy of a binary classification.\n",
        "    Parameters:\n",
        "      - n_label0: number of \"0\"-labeled records\n",
        "      - n_label1: number of \"1\"-labeled records\n",
        "  '''\n",
        "  ####################################\n",
        "  #Írja ide a szükséges forráskódot:\n",
        "\n",
        "  ####################################\n",
        "  return h"
      ],
      "metadata": {
        "id": "G0--fTXI6WfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Ellenőrzés*:\n",
        "\n",
        "Helyes implmentáció esetén a következő cella lefuttatása után rendre kb. a következő eredményt kell kapnia:\n",
        "\n",
        "`[0.0, 1.0, 0.8113]`"
      ],
      "metadata": {
        "id": "7zOIMG3SXciv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entropies = [get_entropy(12, 0), get_entropy(6, 6), get_entropy(3, 9)]\n",
        "print(entropies)"
      ],
      "metadata": {
        "id": "ck-ihjJ5XV0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Információnyereség és struktúratanulás**\n",
        "\n",
        "Specifikáljunk most egy igen egyszerű, mohó módszert döntési fák tanulására!\n",
        "\n",
        "Jelöljük $H(L)$-lel a kiindulási entrópiát, és végezzünk el egy $x$ tulajdonság menti felosztást $x \\leq a$ határnál. Vizsgáljuk meg a felosztási határ alatt maradó pontok entrópiáját, és jelöljük ezt $H(L | x \\leq a)$-val. Hasonló módon kapunk egy másik halmazt is a felosztási határ felett, mely entrópiáját $H(L | x > a)$-val jelölhetjük.\n",
        "\n",
        "Vezessük be a következő jelöléseket: $e := |\\{L | x \\leq a\\}|$ és $f := |\\{L | x > a\\}|$ a felosztási határ alá, illetve fölé eső minták számának jelölésére. Természetesen adódik, hogy $|L| = e+f$.\n",
        "\n",
        "A felosztás hatékonysága így nem más, mint $H(L) - \\Big(\\frac{e}{|L|} \\cdot H(L | x \\leq a) + \\frac{f}{|L|} \\cdot H(L | x > a)\\Big)$, amit *információnyereségnek* hívunk. Azaz egy döntés hasznosságát úgy definiálhatjuk, mint a döntés során kialakuló kisebb halmazok (mintaszámmal súlyozott) entrópiájának és a kiindulási entrópiának a különbségét.\n",
        "\n",
        "**Implementáljon egy információnyereség-számító függvényt!** Megoldásához természetesen használja az előző feladatban implementált `get_entropy()` függvényt!"
      ],
      "metadata": {
        "id": "gMJx-4TSeNdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_information_gain(x: np.ndarray, y: np.ndarray, x_separation: float) -> float:\n",
        "  '''\n",
        "    Returns the information gain given a feature set, a label set,\n",
        "    and a separation level.\n",
        "    Parameters:\n",
        "      x: set of features,\n",
        "      y: set of labels,\n",
        "      x_separation: separation level\n",
        "  '''\n",
        "  ####################################\n",
        "  #Írja ide a szükséges forráskódot:\n",
        "\n",
        "  ####################################\n",
        "  return gain"
      ],
      "metadata": {
        "id": "VUyUgfughUru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Ellenőrzés:*\n",
        "\n",
        "Tekintse meg az eddig elkészült megoldásokat a következő cellák futtatásával. A második cella futtatása után használhatóvá válik a csúszka, melynek mozgatása után automatikusan újrafuttatódik a cella."
      ],
      "metadata": {
        "id": "bbir8-iZlNh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_plot0 = np.random.normal(0, 4.5, 50)\n",
        "x_plot1 = np.random.normal(10, 4.5, 50)\n",
        "y_plot0 = np.random.normal(0, 3, 50)\n",
        "y_plot1 = np.random.normal(0, 3, 50)\n",
        "\n",
        "best_gain, best_gain_x = 0, 0"
      ],
      "metadata": {
        "id": "gAh1BL48neFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Egy döntés {run: \"auto\"}\n",
        "\n",
        "slider = 0.0 # @param {type: \"slider\", min:-10, max: 20, step: 0.5}\n",
        "\n",
        "#plotting:\n",
        "plt.scatter(x_plot0, y_plot0, marker=\"o\", color=\"tab:red\")\n",
        "plt.scatter(x_plot1, y_plot1, marker=\"x\", color=\"navy\")\n",
        "plt.vlines(x = slider, ymin=-9, ymax=9, linewidth=3, alpha=0.6, color=\"k\")\n",
        "plt.xlim(-10, 20)\n",
        "plt.ylim(-10, 10)\n",
        "\n",
        "#computing information gain:\n",
        "x = np.concatenate([x_plot0, x_plot1])\n",
        "y = [0]*50+[1]*50\n",
        "act_gain = get_information_gain(x, y, slider)\n",
        "if act_gain>best_gain:\n",
        "  best_gain = act_gain\n",
        "  best_gain_x = slider\n",
        "\n",
        "#printing gains:\n",
        "print(f\"Actual gain: {act_gain:.4f}\\nBest gain so far: {best_gain:.4f} @ x={best_gain_x}\")"
      ],
      "metadata": {
        "id": "JWv-85nKlMVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ebből talán már következik is egy mohó algoritmus: vegyük szisztematikusan az *összes lehetséges* szeparációt, és válasszuk ezek közül azt, aminél az információnyereség maximális. Jegyezzük fel a döntési tulajdonságot, és a döntési határt, ugyanis ez lesz a döntési fánk *döntési csomópontja*. A szeparáció által létrejött két kisebb halmazunk (melyek nem feltételnül rendezettek). Amennyiben ezek egyike teljesen rendezett, azaz csak egyféle címkét tartalmaz, így entrópiája 0.0, akkor az a döntési fa egy levele, azaz egy adekvát *döntés* lesz. Ellenkező esetben még mindig egy rendezetlen halmazzal van dolgunk, így az algoritmust ezen a részhalmazon rekurzíve folytatjuk tovább, és a korábbi döntési csomópont egyik gyerekeként fogjuk szerepeltetni az általa kapott eredményeket (részfát).\n",
        "\n",
        "Alapvetően ez az algoritmus persze nem lesz optimális, hiszen a kapott döntési fa komplexitása túlságosan nagy lesz, mely ront a fa általánosító képességén. A kialakult fát optimálissá lehet tenni csomópontok összevonásával, a döntési fa nyírásával (pruning)."
      ],
      "metadata": {
        "id": "_Q3VNULLLBFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Döntési fa tanítása**\n",
        "\n",
        "Természetesen a fent említett algoritmusnak létezik hatékony implementációja. Jelen laboron az `sklearn` sokoldalú MI-s Python-csomag által biztosított `DecisionTreeClassifier` használatával fogunk megismerkedni.\n",
        "\n",
        "A következőkben egy használtautó-adatbázissal fogunk dolgozni. Az adatbázis különböző járművek rekordjait tartalmazza, melyet egy használtautó-kereskedő kínál. A kereskedő egyik ügyfele megjelölte *valamilyen szempont* szerint azon járműveket, melyeket meg szeretne tekinteni. A feladatunk, hogy megtanuljuk a vásárló szempontjait (így további, számára tetsző autókat is tudunk neki mutatni).\n",
        "\n",
        "**Első lépésként töltse be és tekintse át az adathalmazt!** Az ügyfél döntéseit a `decision` oszlopban találja, mely `True`, ha meg szeretné tekinteni az adott autót, különben pedig `False` értéket vesz fel. Az adathalmaz részletes ismertetését megtekintheti [itt](https://share.mit.bme.hu/index.php/s/w3okwHpzCF5NSKM)."
      ],
      "metadata": {
        "id": "rVNnhTZdLNZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_df = pd.read_csv('dataset.csv')\n",
        "cars_df"
      ],
      "metadata": {
        "id": "bsZjZ7TELMn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Adatelőkészítés\n",
        "\n",
        "Az `sklearn` csomag `DecisionTreeClassifier` implementációja sajnos nem képes szöveges tulajdonságokat kezelni. Ezért a `manufacturer` és `model` oszlopainkat számmá kell konvertálnunk. Erre a célra jelen esetben megoldás a `sklearn.preprocessing.OrdinalEncoder` [osztály](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#ordinalencoder) használata. Ez sajnos *nem egy általános megoldás*! Jelen esetben a döntési fákon alapuló modell miatt használhatjuk, hiszen itt legfeljebb mélyebb fát kapunk, viszont más modellek (pl. a neurális hálók) kihasználhatják az adatok terében rejlő közelségeket.\n",
        "\n",
        "**Konvertálja számmá a kategorikus tulajdonságokat!** Figyelem: az `OrdinalEncoder` 2-dimenziós bemenetet vár, azonban a `pandas.DataFrame` oszlopai 1-dimenziós, `Series` típust adnak vissza. Az átkonvertáláshoz használható például a következő kód:\n",
        "\n",
        "```python\n",
        "np.array(cars_df[\"manufacturer\"].reshape(-1, 1))\n",
        "```"
      ],
      "metadata": {
        "id": "uvhUCTEoVn1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "oencoder_manufacturer = OrdinalEncoder()\n",
        "oencoder_model = OrdinalEncoder()\n",
        "\n",
        "####################################\n",
        "# Bővítse megfelelően a következő forráskódsorokat:\n",
        "\n",
        "####################################"
      ],
      "metadata": {
        "id": "sa7MYp18XyML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Válassza szét a kapott adathalmazt tanító és tesztadatra a következő cella futtatásával!**"
      ],
      "metadata": {
        "id": "v8xvgIfdZNQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cars_df.drop(columns=[\"decision\"]),              #features\n",
        "    cars_df[\"decision\"],                             #labels\n",
        "    test_size=0.2                                    #80% -> train, 20% -> test\n",
        ")"
      ],
      "metadata": {
        "id": "u_1jHtFcZgyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Tanítás\n",
        "\n",
        "**Az adatok előkészítése után tanítsa be a döntési fát!** Első körben egy 1-mélységű fát fogunk készíteni, és elemezzük annak osztályozó képességét. Jelen laborban az entrópiát (`entropy`) kell rendezőelvnek tekinteni. Futtassa le a következő cellát a döntési fa tanításához!"
      ],
      "metadata": {
        "id": "W5DuPdhZae6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")\n",
        "dtree = dtree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rCxFkO5mbcSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tekintsük meg az elkészült döntési fát!**"
      ],
      "metadata": {
        "id": "XEt20BUvcDDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A döntési fa ábrázolása\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dtree, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = X_train.columns, class_names=['nem tekintjük meg','megtekintjük'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "VF07jxICcHc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Döntési fa tesztelése\n",
        "\n",
        "Amint látható, az 1-mélységű fa egyik levelében még vegyesen találhatóak jó és nem megfelelő gépkocsik (lásd: entropy$\\neq$0, a value vegyesen tartalmaz mintákat). **A következő cella futtatásával végezzen el egy következtető lépést a tesztadatokon!**"
      ],
      "metadata": {
        "id": "3EztqjuHbqA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = dtree.predict(X_test)"
      ],
      "metadata": {
        "id": "cAgg_S0-b6RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahhoz, hogy megítéljük, mennyire sikerült jól osztályozni az egyes járműveket, különböző metrikákat használhatunk. Szerencsére az `sklearn` csomag számos kiértékelési mértéket implementál, tekintsünk meg most ezek közül néhányat!"
      ],
      "metadata": {
        "id": "-2tZntzFb9PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "UWFp6Y8jdGrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amint láthatjuk, a modellünk egészen pontos (*accuracy*), azonban még bizonyosan vannak rosszul besorolt járművek. **Tekintse meg, hogy mennyi és milyen típusú hibát vét az első döntési faimplementációnk a következő cella futtatásával!**"
      ],
      "metadata": {
        "id": "AHi88-2_dwfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
      ],
      "metadata": {
        "id": "AVdltC7_ehv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Mélyebb döntési fa\n",
        "\n",
        "Ahogy látható, az 1-mélységű döntési fa még vét hibákat. **Implementáljon most egy mélyebb, pl. 5-mélységű fát!**"
      ],
      "metadata": {
        "id": "v9Svq1JrfdMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deeper_dtree = DecisionTreeClassifier(max_depth=5, criterion=\"entropy\") #írja ide a szükséges forráskódot!\n",
        "deeper_dtree = deeper_dtree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TQGXY3QYgRDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ellenőrizzük a kapott, mélyebb döntési fa képességeit!**"
      ],
      "metadata": {
        "id": "9jYSydLBgg7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deeper_y_pred = deeper_dtree.predict(X_test)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, deeper_y_pred)"
      ],
      "metadata": {
        "id": "qJUxJ0GPgtmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ez a döntési fa elvileg már nem vét hibát. Az ügyfél eredeti szempontjai a következők voltak:\n",
        "- legyen az ára 3.500.000 Ft-nál olcsóbb, és\n",
        "- legyen 100.000 km-nél kisebb a futásteljesítménye, és\n",
        "- 2007-nél újabb gyártású legyen.\n",
        "\n",
        "**Tekintse meg, hogy ehhez képest milyen szabályokat tárt fel a döntési fa!**"
      ],
      "metadata": {
        "id": "P3y24KaMhGC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = StringIO()\n",
        "export_graphviz(deeper_dtree, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = X_train.columns, class_names=['nem tekintjük meg','megtekintjük'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "zArZuoh1hrCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **3. Feladatbeadás**\n",
        "\n",
        "A [Moodle](edu.vik.bme.hu) rendszerén keresztül beadandó feladat, hogy implementáljon egy döntési fákra épülő osztályozó rendszert!\n",
        "\n",
        "A megoldásnak bemenő paraméterként fogadnia kell az `X_train`, `y_train` tulajdonság- és címkelistákat, valamint egy `X_test` tesztbemenetet. A tesztbemenetre kimenetként elő kell állítani az `y_pred` előrejelzést.\n",
        "\n",
        "Ennek szofisztikált megvalósítását szolgálja az `sklearn` csomagból elérhető [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#pipeline) megoldás. A `Pipeline`-ba különböző adatelőkészítő, adatfeldolgozó, osztályozó, előrejelző komponenseket gyűjthetünk össze (melyek akár az `sklearn` könyvtárán kívülről is származhatnak).\n",
        "\n",
        "A `Pipeline`-os feldolgozást megkönnyítendő létezik az `sklearn` könyvtárban egy [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) osztály, mely számára specifikálhatjuk, hogy a bemenet mely oszlopaira milyen transzformációkat (pl. `OrdinalEncoder`) kell elvégezni, illetve elő lehet írni, hogy a maradék oszlopokkal mi történjen. Például ha át akarjuk őket engedni változatlanul, akkor azt a `remainder = 'passthrough'` paraméterezéssel beállíthatjuk.\n",
        "\n",
        "Így tehát a beküldendő megoldáshoz javasolt (de nem kötelező) `Pipeline` megoldást a következő ábra mutatja be:\n",
        "\n",
        "![pipeline](https://share.mit.bme.hu/index.php/apps/files_sharing/publicpreview/67GGgTG9iLDr52b?file=/&fileId=3823392&x=1920&y=1080&a=true&etag=9211e19084e25e2a8263922a1ba18ca9)\n",
        "\n",
        "**Figyelem!** Előfordulhat, hogy a teszteléskor használt címkéket az `OrdinalEncoder` még nem ismeri. Ilyenkor egy hibakezelési megoldás, hogy egy alapértelmezett értékkel helyettesíti az encoder az ismeretlen címkét. Ezt például az alábbi kóddal lehet elérni:\n",
        "\n",
        "```python\n",
        "OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = -1)\n",
        "```\n",
        "\n",
        "Az alábbiakban megtalálja a beadandó `decision_tree_lab_solution.py` fájl szkeletonját (további csomagok importálására elvileg nincsen szükség):"
      ],
      "metadata": {
        "id": "R8UTL5eNA9XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def predict(X_train, y_train, X_test):\n",
        "    ######################################################\n",
        "    #Írja ide a szükséges forráskódot!\n",
        "\n",
        "    ######################################################\n",
        "    return pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "EKeRDXqebpKl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}