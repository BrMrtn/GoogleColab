{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLdZfIjuw0Cwix0KjBLpbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrMrtn/GoogleColab/blob/main/DeepLearning/KHF4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A cél egy előtanított CNN háló tovább tanítása.\n",
        " - Válassz ki három tetszőleges kategóriát a Google Open Images Dataset-ből\n",
        "és tölts le 400 képet kategóriánként.\n",
        " - Tölts be tetszőleges előtanított hálót (pl. Inception v3, VGG, ResNet) és tanítsd tovább (transfer learning) a kiválasztott három kategóriával:\n",
        "     - Előbb csak a végső fully-connected rétegek tanuljanak.\n",
        "     - Majd az így tovább tanított hálót tanítsd még tovább úgy, hogy a konvolúciós rétegek felsőbb rétegei is tanulnak (az alsóbbak nem).\n",
        " - Egy elkülönített teszt adatbázison, a kiválasztott három kategóriával értékeld ki a megoldás hatékonyságát. A tanító adatbázisban 200-200, a validációsban 100-100, a tesztben 100-100 kép legyen. Egy képet csak egy adatbázis részben használj fel, azonos előfeldolgozó eljárást használj, mint amit az előtanított hálónál alkalmaztak."
      ],
      "metadata": {
        "id": "Iyv-TInWEgp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Tensorflow datasets segítségével hozzáférhetünk a Google Open Image Datasethez."
      ],
      "metadata": {
        "id": "RUb0UzoFD5dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone"
      ],
      "metadata": {
        "id": "Dg9B6yFvp-xk",
        "outputId": "ac4e4d79-16d4-47a6-b4f4-91740f77db70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fiftyone\n",
            "  Downloading fiftyone-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.12.3)\n",
            "Collecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.35.73-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.5.0)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.15)\n",
            "Collecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading hypercorn-0.17.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.4)\n",
            "Collecting kaleido!=0.2.1.post1 (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.8.0)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (11.0.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.24.1)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo<4.9,>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2024.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2024.9.11)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (75.1.0)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting starlette>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting strawberry-graphql (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.253.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pydash (from fiftyone)\n",
            "  Downloading pydash-8.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting fiftyone-brain<0.18,>=0.17.0 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-1.1.7.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.14,>=0.13.0 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.13.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.10.0.84)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.2)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
            "Collecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.12.2)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of motor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.5.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (9.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<4.9,>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.27.2)\n",
            "Collecting dill (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.8.2)\n",
            "Collecting rarfile (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.16.0)\n",
            "Collecting sortedcontainers (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.6)\n",
            "Collecting botocore<1.36.0,>=1.35.73 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.35.73-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.2.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fiftyone) (2024.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.5.0)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql->fiftyone)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.14,>=0.13.0->fiftyone) (24.2.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.14,>=0.13.0->fiftyone) (3.4.0)\n",
            "Downloading fiftyone-1.0.2-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Downloading fiftyone_brain-0.17.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hypercorn-0.17.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.5.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Downloading voxel51_eta-0.13.0-py2.py3-none-any.whl (943 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.1/943.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.73-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pydash-8.0.4-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading strawberry_graphql-0.253.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading botocore-1.35.73-py3-none-any.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n",
            "Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: fiftyone-db\n",
            "  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.7-py3-none-manylinux1_x86_64.whl size=42156157 sha256=a97413973a51811a91be1a7a763c2fe1e62a6e7f658ef37c0892a52a71cd06ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/8b/e8/4f778229cacacc9c4e9871a9e0d7bce98fc99b8c01af0ea669\n",
            "Successfully built fiftyone-db\n",
            "Installing collected packages: texttable, sseclient-py, sortedcontainers, pprintpp, kaleido, brotli, xmltodict, wsproto, taskgroup, retrying, rarfile, pyzstd, pyppmd, pydash, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, graphql-core, ftfy, fiftyone-db, dnspython, dill, dacite, argcomplete, aiofiles, strawberry-graphql, starlette, pymongo, py7zr, h2, botocore, voxel51-eta, universal-analytics-python3, sse-starlette, s3transfer, motor, mongoengine, hypercorn, fiftyone-brain, boto3, fiftyone\n",
            "Successfully installed aiofiles-24.1.0 argcomplete-3.5.1 boto3-1.35.73 botocore-1.35.73 brotli-1.1.0 dacite-1.7.0 dill-0.3.9 dnspython-2.7.0 fiftyone-1.0.2 fiftyone-brain-0.17.0 fiftyone-db-1.1.7 ftfy-6.3.1 graphql-core-3.2.5 h2-4.1.0 hpack-4.0.0 hypercorn-0.17.3 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.5.3 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.21.0 pydash-8.0.4 pymongo-4.8.0 pyppmd-1.1.0 pyzstd-0.16.2 rarfile-4.2 retrying-1.3.4 s3transfer-0.10.4 sortedcontainers-2.4.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.41.3 strawberry-graphql-0.253.0 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.13.0 wsproto-1.2.0 xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "classes = [\"Drink\", \"Weapon\", \"Bird\"]\n",
        "\n",
        "train_dataset = fo.Dataset(\"train_dataset\")\n",
        "train_dataset.dataset_name = \"train_dataset\"\n",
        "\n",
        "test_dataset = fo.Dataset(\"test_dataset\")\n",
        "test_dataset.dataset_name = \"test_dataset\"\n",
        "\n",
        "validation_dataset = fo.Dataset(\"validation_dataset\")\n",
        "validation_dataset.dataset_name = \"validation_dataset\""
      ],
      "metadata": {
        "id": "g9s-lY0lhoBj",
        "outputId": "78be8c86-4191-44a5-e6ce-683e0b037d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Dataset name 'train_dataset' is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-97ee1c4e1d0c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Drink\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Weapon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Bird\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train_dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/core/singletons.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, name, _create, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         ):\n\u001b[1;32m     35\u001b[0m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_create\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m  \u001b[0;31m# `__init__` may have changed `name`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/core/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, persistent, overwrite, _create, _virtual, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_create\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             doc, sample_doc_cls, frame_doc_cls = _create_dataset(\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/core/dataset.py\u001b[0m in \u001b[0;36m_create_dataset\u001b[0;34m(obj, name, persistent, _patches, _frames, _clips, _src_collection)\u001b[0m\n\u001b[1;32m   8094\u001b[0m     \u001b[0m_src_collection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8095\u001b[0m ):\n\u001b[0;32m-> 8096\u001b[0;31m     \u001b[0mslug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_dataset_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8098\u001b[0m     \u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/core/dataset.py\u001b[0m in \u001b[0;36m_validate_dataset_name\u001b[0;34m(name, skip)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mclashing_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclashing_name_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclashing_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset name '{name}' is not available\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Dataset name 'train_dataset' is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in classes:\n",
        "  cur_train_dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"classifications\"],\n",
        "    classes=[cls],\n",
        "    max_samples=200,\n",
        "    dataset_name=cls+\"_train_dataset\",\n",
        "  )\n",
        "\n",
        "  cur_test_dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"test\",\n",
        "    label_types=[\"classifications\"],\n",
        "    classes=[cls],\n",
        "    max_samples=100,\n",
        "    dataset_name=cls+\"_test_dataset\",\n",
        "  )\n",
        "\n",
        "  cur_validation_dataset = foz.load_zoo_dataset(\n",
        "    \"open-images-v7\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"classifications\"],\n",
        "    classes=[cls],\n",
        "    max_samples=100,\n",
        "    dataset_name=cls+\"_validation_dataset\",\n",
        "  )\n",
        "\n",
        "  train_dataset.add_samples(cur_train_dataset)\n",
        "  test_dataset.add_samples(cur_test_dataset)\n",
        "  validation_dataset.add_samples(cur_validation_dataset)"
      ],
      "metadata": {
        "id": "UJ7m7l9jqB1a",
        "outputId": "58fed2d1-a6d2-4670-cc45-2cebc4d51407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/open-images-v7/train' if necessary\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7a015bbc5d80>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'train' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'open-images-v7-train-200'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'open-images-v7-train-200'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'test' to '/root/fiftyone/open-images-v7/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'test' to '/root/fiftyone/open-images-v7/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'test' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'test' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'open-images-v7-test-100'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'open-images-v7-test-100'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/open-images-v7/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.openimages:Necessary images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'open-images-v7-validation-100'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'open-images-v7-validation-100'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 200/200 [3.3s elapsed, 0s remaining, 75.3 samples/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 200/200 [3.3s elapsed, 0s remaining, 75.3 samples/s]       \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Dataset' object has no attribute 'add_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3446af24de74>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_train_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_validation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/core/dataset.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset '%s' is deleted\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'add_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.shuffle()\n",
        "test_dataset.shuffle()\n",
        "validation_dataset.shuffle()"
      ],
      "metadata": {
        "id": "hxzNIzOZv_Tg",
        "outputId": "4540ae1a-01ac-4417-a5a7-5a82a7e6e5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset:     validation_dataset\n",
              "Media type:  image\n",
              "Num samples: 300\n",
              "Sample fields:\n",
              "    id:               fiftyone.core.fields.ObjectIdField\n",
              "    filepath:         fiftyone.core.fields.StringField\n",
              "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
              "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
              "    created_at:       fiftyone.core.fields.DateTimeField\n",
              "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
              "    positive_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
              "    negative_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n",
              "View stages:\n",
              "    1. Shuffle(seed=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show some samples from train_dataset\n",
        "session = fo.launch_app(train_dataset)"
      ],
      "metadata": {
        "id": "PiVF4NRpy_dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(len(classes), activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "id": "f1IxVCe4oi6B",
        "outputId": "b4951095-42df-4267-8d9e-46bea9152373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized data type: x=Name:        train_dataset\nMedia type:  image\nNum samples: 600\nPersistent:  False\nTags:        []\nSample fields:\n    id:               fiftyone.core.fields.ObjectIdField\n    filepath:         fiftyone.core.fields.StringField\n    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n    created_at:       fiftyone.core.fields.DateTimeField\n    last_modified_at: fiftyone.core.fields.DateTimeField\n    positive_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n    negative_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications) (of type <class 'fiftyone.core.dataset.Dataset'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ae36299c5bae>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/__init__.py\u001b[0m in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized data type: x={x} (of type {type(x)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=Name:        train_dataset\nMedia type:  image\nNum samples: 600\nPersistent:  False\nTags:        []\nSample fields:\n    id:               fiftyone.core.fields.ObjectIdField\n    filepath:         fiftyone.core.fields.StringField\n    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n    created_at:       fiftyone.core.fields.DateTimeField\n    last_modified_at: fiftyone.core.fields.DateTimeField\n    positive_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications)\n    negative_labels:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classifications) (of type <class 'fiftyone.core.dataset.Dataset'>)"
          ]
        }
      ]
    }
  ]
}